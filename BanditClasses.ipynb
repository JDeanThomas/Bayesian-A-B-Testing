{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandit Classes and Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rand = np.random.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandits(object):\n",
    "    \"\"\"\n",
    "    This class represents N bandits machines.\n",
    "\n",
    "    parameters:\n",
    "        p_array: a (n,) Numpy array of probabilities >0, <1.\n",
    "\n",
    "    methods:\n",
    "        pull( i ): return the results, 0 or 1, of pulling \n",
    "                   the ith bandit.\n",
    "    \"\"\"\n",
    "    def __init__(self, p_array):\n",
    "        self.p = p_array\n",
    "        self.optimal = np.argmax(p_array)\n",
    "        \n",
    "    def pull(self, i):\n",
    "        #i is which arm to pull\n",
    "        return rand() < self.p[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditEngine(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Implements a online, learning strategy to solve\n",
    "    the Multi-Armed Bandit problem.\n",
    "    \n",
    "    parameters:\n",
    "        bandits: a Bandit class with .pull method\n",
    "        choice_function: accepts a self argument (which gives access to all the variables), and \n",
    "        returns and int between 0 and n-1\n",
    "    methods:\n",
    "        sample_bandits(n): sample and train on n pulls.\n",
    "\n",
    "    attributes:\n",
    "        N: the cumulative number of samples\n",
    "        choices: the historical choices as a (N,) array\n",
    "        bb_score: the historical score as a (N,) array\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, bandits, choice_function, learning_rate=1):\n",
    "        \n",
    "            self.bandits = bandits\n",
    "            self.choice_function = choice_function\n",
    "            self.learning_rate = learning_rate\n",
    "            \n",
    "            n_bandits = len(self.bandits)\n",
    "            self.wins = np.zeros(n_bandits, dtype=np.float64)\n",
    "            self.trials = np.zeros(n_bandits, dtype=np.float64)\n",
    "            self.N = 0\n",
    "            self.choices = []\n",
    "            self.score = []\n",
    "        \n",
    "    def sample_bandits(self, n=1):\n",
    "        \n",
    "        score = np.zeros(n)\n",
    "        choices = np.zeros(n)\n",
    "        \n",
    "        for k in range(n):\n",
    "            #sample from the bandits's priors, and select the largest sample\n",
    "            choice = self.choice_function(self)\n",
    "            \n",
    "            #sample the chosen bandit\n",
    "            result = self.bandits.pull(choice)\n",
    "            self.wins[choice] = self.learning_rate * self.wins[choice] + result\n",
    "            self.trials[choice] = self.learning_rate * self.trials[choice] + 1\n",
    "            score[k] = result \n",
    "            self.N += 1\n",
    "            choices[k] = choice\n",
    "            \n",
    "        self.score = np.r_[self.score, score]\n",
    "        self.choices = np.r_[self.choices, choices]\n",
    "        return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
